{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27991036",
   "metadata": {},
   "source": [
    "# GPT-Dev\n",
    "\n",
    "Experiments before they're integrated into the main codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79fd75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877482a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD = os.getcwd()\n",
    "DATA_DIR = os.path.join(PWD, \"data\")\n",
    "INPUT_DATA_URL = (\"https://raw.githubusercontent.com/karpathy/char-rnn/\"\n",
    "                  \"master/data/tinyshakespeare/input.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ebceb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_input_data() -> str:\n",
    "    \"\"\"Gets the input data, caching it for easy access.\"\"\"\n",
    "    input_file_path = os.path.join(DATA_DIR, \"input.txt\")\n",
    "    if not os.path.exists(input_file_path):\n",
    "        with open(input_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(requests.get(INPUT_DATA_URL).text)\n",
    "    \n",
    "    with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a95dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = fetch_input_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3231b66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(len(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf06e2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(input_text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b239148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = {c: i for i, c in enumerate(chars)}\n",
    "int_to_string = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: \"\".join([int_to_string[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf486f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hello\"))\n",
    "print(decode(encode(\"hello\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169c93d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115394,) mlx.core.int64\n",
      "array([18, 47, 56, ..., 8, 0, 0], dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "data = mx.array(encode(input_text), dtype=mx.int64)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e169755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fae276d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 47, 56, ..., 15, 47, 58], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c963b767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is array([18], dtype=int64) the target is 47\n",
      "when input is array([18, 47], dtype=int64) the target is 56\n",
      "when input is array([18, 47, 56], dtype=int64) the target is 57\n",
      "when input is array([18, 47, 56, 57], dtype=int64) the target is 58\n",
      "when input is array([18, 47, 56, 57, 58], dtype=int64) the target is 1\n",
      "when input is array([18, 47, 56, 57, 58, 1], dtype=int64) the target is 15\n",
      "when input is array([18, 47, 56, ..., 58, 1, 15], dtype=int64) the target is 47\n",
      "when input is array([18, 47, 56, ..., 1, 15, 47], dtype=int64) the target is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t].item()\n",
    "    print(f\"when input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4de3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.random.seed(1337)\n",
    "batch_size = 4 # number of independent sequences to train on in parallel\n",
    "block_size = 8 # maximum context length for predictions\n",
    "\n",
    "def get_batch(split: Literal[\"train\", \"val\"]) -> tuple[mx.array, mx.array]:\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = mx.random.randint(0, len(data) - block_size, [batch_size])\n",
    "    # gets `batch_size` blocks stacked\n",
    "    x = mx.stack([data[i.item():i.item() + block_size] for i in ix])\n",
    "    # it's shifted to compute the target vectorized\n",
    "    y = mx.stack([data[i.item() + 1:i.item() + block_size + 1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5c13e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "(4, 8)\n",
      "array([[47, 45, 52, ..., 47, 52, 1],\n",
      "       [57, 0, 16, ..., 1, 57, 43],\n",
      "       [40, 56, 53, ..., 11, 1, 40],\n",
      "       [1, 46, 39, ..., 1, 61, 39]], dtype=int64)\n",
      "targets:\n",
      "(4, 8)\n",
      "array([[45, 52, 57, ..., 52, 1, 45],\n",
      "       [0, 16, 47, ..., 57, 43, 43],\n",
      "       [56, 53, 49, ..., 1, 40, 43],\n",
      "       [46, 39, 60, ..., 61, 39, 56]], dtype=int64)\n",
      "when input is array([47], dtype=int64) the target is 45\n",
      "when input is array([47, 45], dtype=int64) the target is 52\n",
      "when input is array([47, 45, 52], dtype=int64) the target is 57\n",
      "when input is array([47, 45, 52, 57], dtype=int64) the target is 1\n",
      "when input is array([47, 45, 52, 57, 1], dtype=int64) the target is 47\n",
      "when input is array([47, 45, 52, 57, 1, 47], dtype=int64) the target is 52\n",
      "when input is array([47, 45, 52, ..., 1, 47, 52], dtype=int64) the target is 1\n",
      "when input is array([47, 45, 52, ..., 47, 52, 1], dtype=int64) the target is 45\n",
      "when input is array([57], dtype=int64) the target is 0\n",
      "when input is array([57, 0], dtype=int64) the target is 16\n",
      "when input is array([57, 0, 16], dtype=int64) the target is 47\n",
      "when input is array([57, 0, 16, 47], dtype=int64) the target is 42\n",
      "when input is array([57, 0, 16, 47, 42], dtype=int64) the target is 1\n",
      "when input is array([57, 0, 16, 47, 42, 1], dtype=int64) the target is 57\n",
      "when input is array([57, 0, 16, ..., 42, 1, 57], dtype=int64) the target is 43\n",
      "when input is array([57, 0, 16, ..., 1, 57, 43], dtype=int64) the target is 43\n",
      "when input is array([40], dtype=int64) the target is 56\n",
      "when input is array([40, 56], dtype=int64) the target is 53\n",
      "when input is array([40, 56, 53], dtype=int64) the target is 49\n",
      "when input is array([40, 56, 53, 49], dtype=int64) the target is 43\n",
      "when input is array([40, 56, 53, 49, 43], dtype=int64) the target is 11\n",
      "when input is array([40, 56, 53, 49, 43, 11], dtype=int64) the target is 1\n",
      "when input is array([40, 56, 53, ..., 43, 11, 1], dtype=int64) the target is 40\n",
      "when input is array([40, 56, 53, ..., 11, 1, 40], dtype=int64) the target is 43\n",
      "when input is array([1], dtype=int64) the target is 46\n",
      "when input is array([1, 46], dtype=int64) the target is 39\n",
      "when input is array([1, 46, 39], dtype=int64) the target is 60\n",
      "when input is array([1, 46, 39, 60], dtype=int64) the target is 43\n",
      "when input is array([1, 46, 39, 60, 43], dtype=int64) the target is 1\n",
      "when input is array([1, 46, 39, 60, 43, 1], dtype=int64) the target is 61\n",
      "when input is array([1, 46, 39, ..., 43, 1, 61], dtype=int64) the target is 39\n",
      "when input is array([1, 46, 39, ..., 1, 61, 39], dtype=int64) the target is 56\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch(\"train\")\n",
    "\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "# We can observe they match but yb is shifted by one\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t].item()\n",
    "        print(f\"when input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "786cde99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.nn as nn\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def __call__(self, idx: mx.array) -> mx.array:\n",
    "        return self.token_embedding(idx)\n",
    "    \n",
    "    def generate(self, idx: mx.array, max_new_tokens: int) -> mx.array:\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            idx_next = mx.random.categorical(logits, num_samples=1, axis=-1)\n",
    "            idx = mx.concatenate([idx, idx_next], axis=1)\n",
    "        # this is actually going to return 101 tokens since the input counts\n",
    "        return idx\n",
    "\n",
    "\n",
    "def loss_fn(model: nn.Module, x: mx.array, y: mx.array) -> mx.array:\n",
    "    return mx.mean(nn.losses.cross_entropy(model(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aada610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8, 65) ()\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(vocab_size)\n",
    "logits = model(xb)\n",
    "loss = loss_fn(model, xb, yb)\n",
    "print(logits.shape, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55a186b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n.P.e'wn,CZsvq gP-f$fvW3aypokkuSEz?Paw:YCj?M;x\\npctpxMvdJMlTZrmCZhPRjYRJUfTgldWbqlwXxc CHIWuAFYEBlwJrb\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = mx.zeros((1, 1), dtype=mx.int64)\n",
    "decode(model.generate(input, 100).reshape(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b45d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4868011474609375\n"
     ]
    }
   ],
   "source": [
    "import mlx.optimizers as optim\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n",
    "optimizer = optim.AdamW(learning_rate=1e-3)\n",
    "\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    loss, grads = loss_and_grad_fn(model, xb, yb)\n",
    "    optimizer.update(model, grads)\n",
    "    mx.eval(model.parameters(), optimizer.state)\n",
    "\n",
    "print(loss_fn(model, *get_batch(\"train\")).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06c6d0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RI d tloul ilie om toour t\n",
      "IEmbe d, hthithot whars shieiststh'stet schontoumy mced bliserved isty HE\n"
     ]
    }
   ],
   "source": [
    "input = mx.zeros((1, 1), dtype=mx.int64)\n",
    "print(decode(model.generate(input, 100).reshape(-1).tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523187f",
   "metadata": {},
   "source": [
    "## Mathematical Trick in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba499ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.random.seed(1337)\n",
    "B, T, C = shape = [4, 8, 2]  # Batch, Time, Channels\n",
    "x = mx.random.normal(shape)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f02e22ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.20038, -0.102716],\n",
       "        [1.32946, -0.714395],\n",
       "        [0.647708, -0.289021],\n",
       "        ...,\n",
       "        [0.098629, -0.212],\n",
       "        [0.0613602, -0.206279],\n",
       "        [-0.0196391, -0.192657]],\n",
       "       [[-0.88286, 1.90818],\n",
       "        [0.272445, 1.62297],\n",
       "        [-0.025046, 1.02757],\n",
       "        ...,\n",
       "        [0.144306, 0.739237],\n",
       "        [0.14616, 0.550131],\n",
       "        [-0.16644, 0.507876]],\n",
       "       [[0.0548329, -0.871395],\n",
       "        [0.0152365, -0.370004],\n",
       "        [-0.421962, -0.2805],\n",
       "        ...,\n",
       "        [-0.432742, 0.136636],\n",
       "        [-0.419489, 0.203147],\n",
       "        [-0.342733, 0.326026]],\n",
       "       [[-0.977191, 0.433173],\n",
       "        [-0.394541, 0.021305],\n",
       "        [-0.432306, -0.325967],\n",
       "        ...,\n",
       "        [0.00372714, -0.381902],\n",
       "        [0.0797167, -0.157575],\n",
       "        [0.1951, -0.193353]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = mx.zeros(shape)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]  # -> [t, C]\n",
    "        xbow[b, t] = mx.mean(xprev, axis=0)\n",
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "285b2547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True, dtype=bool)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = mx.tril(mx.ones((T, T)))\n",
    "wei = wei / wei.sum(1, keepdims=True)  # normalize\n",
    "xbow2 = wei @ x\n",
    "mx.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebcc9fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True, dtype=bool)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = mx.tril(mx.ones((T, T)))\n",
    "wei = mx.zeros((T, T))\n",
    "wei = mx.where(tril == 0, float(\"-inf\"), wei) # this replaced masked_fill\n",
    "wei = mx.softmax(wei, axis=-1)\n",
    "xbow3 = wei @ x\n",
    "mx.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56da25d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention\n",
    "mx.random.seed(1337)\n",
    "B, T, C = shape = [4, 8, 32]  # Batch, Time, Channels\n",
    "x = mx.random.normal(shape)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)  # [B, T, head_size]\n",
    "q = query(x)  # [B, T, head_size]\n",
    "wei = q @ mx.transpose(k, axes=[0, -1, -2]) # [B, T, head_size] @ [B, head_size, T] -> [B, T, T]\n",
    "\n",
    "tril = mx.tril(mx.ones((T, T)))\n",
    "wei = mx.where(tril == 0, float(\"-inf\"), wei)\n",
    "wei = mx.softmax(wei, axis=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23052c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0.856269, 0.143731, 0, ..., 0, 0, 0],\n",
       "       [0.431043, 0.00779574, 0.561161, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0.219786, 0.260875, 0.325269, ..., 0.00784806, 0, 0],\n",
       "       [0.390585, 0.0546818, 0.0550628, ..., 0.0648744, 0.143865, 0],\n",
       "       [0.00486556, 0.0906292, 0.136023, ..., 0.183027, 0.0706174, 0.0119941]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb4d7e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dcf6b",
   "metadata": {},
   "source": [
    "**To understand the code above**, I find it useful to consider what various\n",
    "parts of the code are doing.  \n",
    "\n",
    "**Channels**  \n",
    "_`C` represents the number of channels._  \n",
    "\n",
    "Channels serve as a way to encode all sorts of information.\n",
    "It does not matter what they encode, likely does not have a human\n",
    "interpretation.  \n",
    "These representations are one aspects of what the network is learning.\n",
    "For example, a channel may encode \"being a consonant\".  \n",
    "\n",
    "**Keys and Queries**  \n",
    "Assuming we have a channel that represents \"being a consonant\".  \n",
    "\n",
    "_A query represents what we're looking for._  \n",
    "For example, a query may represent looking for a consonant at any position,\n",
    "which would be encoded as a uniform distribution over all tokens in the\n",
    "consonant channel in the query.  \n",
    "A query could also be looking for consonants at specific positions/regions,\n",
    "which woudl be encoded as higher values at those positions.  \n",
    "\n",
    "_The key follows a similar logic, but represents what each token is,_\n",
    "_in the channel._  \n",
    "A consonant would have a higher value at its position, in the key vector,\n",
    "in the consonant channel.  \n",
    "\n",
    "The product between keys and queries represents the affinity between what\n",
    "we're looking for and what we have.  \n",
    "A _consonant query_ with a high value at the first position, will have a strong\n",
    "affinity if the _consonant key_ also has a higher value at the first position.  \n",
    "\n",
    "**Values**\n",
    "_Values represent what gets communicated to the next layer._  \n",
    "\n",
    "Values are a simple linear transformation of the input.  \n",
    "Linear transformations allow the network to transform the inputs into a more\n",
    "useful representation (from a network perspective).  \n",
    "For example, maybe not all tokens are equally useful to the output, learning\n",
    "what to consider or not is helpful.  \n",
    "\n",
    "It can also be useful to transform the inputs into different dimensions.  \n",
    "This linear transformation is what transforms the input into the\n",
    "representation at the next level.  \n",
    "\n",
    "**Outputs**\n",
    "_Combines `values`, `keys` and `queries` to represent what is relevant to the_\n",
    "_next layer._  \n",
    "\n",
    "`keys` and `queries` are combined to create an affinity of what is important\n",
    "for the current token (`> wei`). `values` represent what to communicate to the\n",
    "next layer, but has to be combined with `wei` to \"select\" only relevant\n",
    "information.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96cfe8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cdf563",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecccb92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
